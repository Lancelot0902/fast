# encoding: utf-8
"""
@author:  liaoxingyu
@contact: liaoxingyu2@jd.com
"""

import copy
import itertools
from collections import defaultdict
from typing import Optional

import numpy as np
from torch.utils.data.sampler import Sampler

from fastreid.utils import comm


def no_index(a, b):
    assert isinstance(a, list)
    return [i for i, j in enumerate(a) if j != b]


def reorder_index(batch_indices, world_size):
    r"""Reorder indices of samples to align with DataParallel training.
    In this order, each process will contain all images for one ID, triplet loss
    can be computed within each process, and BatchNorm will get a stable result.
    Args:
        batch_indices: A batched indices generated by sampler
        world_size: number of process
    Returns:

    """
    mini_batchsize = len(batch_indices) // world_size
    reorder_indices = []
    for i in range(0, mini_batchsize):
        for j in range(0, world_size):
            reorder_indices.append(batch_indices[i + j * mini_batchsize])
    return reorder_indices

class DomainSingleNaiveIdentitySampler(Sampler):
    """
    Randomly sample N identities of a single domain, then for each identity,
    randomly sample K instances, therefore batch size is N*K.
    Args:
    - data_source (list): list of (img_path, pid, camid).
    - num_instances (int): number of instances per identity in a batch.
    - batch_size (int): number of examples in a batch.
    """

    def __init__(self, data_source: str, mini_batch_size: int, num_instances: int, seed: Optional[int] = None):
        self.data_source = data_source
        self.num_instances = num_instances
        self.num_pids_per_batch = mini_batch_size // self.num_instances

        self._rank = comm.get_rank()
        self._world_size = comm.get_world_size()
        self.batch_size = mini_batch_size * self._world_size

        self.pid_index = defaultdict(list)
        self.domain = defaultdict(list)

        for index, info in enumerate(data_source):
            pid = info[1]
            # did = info[1].split('_')[0]
            self.pid_index[pid].append(index)
            # self.domain[did].append(pid)

        self.pids = sorted(list(self.pid_index.keys()))

        for pid in self.pids:
            did = pid.split('_')[0]
            self.domain[did].append(pid)

        self.num_identities = len(self.pids)

        if seed is None:
            seed = comm.shared_random_seed()
        self._seed = int(seed)

    def __iter__(self):
        start = self._rank
        yield from itertools.islice(self._infinite_indices(), start, None, self._world_size)

    def _infinite_indices(self):
        np.random.seed(self._seed)
        while True:
            avl_pids = copy.deepcopy(self.pids)
            domain = copy.deepcopy(self.domain)
            batch_idxs_dict = {}

            batch_indices = []
            while len(avl_pids) >= self.num_pids_per_batch and domain:
                selected_domain = np.random.choice(list(domain.keys()), 1, replace=False).tolist()[0]
                selected_pids = np.random.choice(domain[selected_domain], self.num_pids_per_batch, replace=False).tolist()
                # selected_pids = np.random.choice(avl_pids, self.num_pids_per_batch, replace=False).tolist()
                for pid in selected_pids:
                    # Register pid in batch_idxs_dict if not
                    if pid not in batch_idxs_dict:
                        idxs = copy.deepcopy(self.pid_index[pid])
                        if len(idxs) < self.num_instances:
                            idxs = np.random.choice(idxs, size=self.num_instances, replace=True).tolist()
                        np.random.shuffle(idxs)
                        batch_idxs_dict[pid] = idxs

                    avl_idxs = batch_idxs_dict[pid]
                    for _ in range(self.num_instances):
                        batch_indices.append(avl_idxs.pop(0))

                    if len(avl_idxs) < self.num_instances:
                        avl_pids.remove(pid)
                        domain[selected_domain].remove(pid)
                if len(domain[selected_domain]) < self.num_pids_per_batch:
                    del domain[selected_domain]


                if len(batch_indices) == self.batch_size:
                    yield from reorder_index(batch_indices, self._world_size)
                    batch_indices = []


class DomainMultiNaiveIdentitySampler(Sampler):
    """
    Randomly sample N identities of a single domain, then for each identity,
    randomly sample K instances, therefore batch size is N*K.
    Args:
    - data_source (list): list of (img_path, pid, camid).
    - num_instances (int): number of instances per identity in a batch.
    - batch_size (int): number of examples in a batch.
    """

    def __init__(self, data_source: str, mini_batch_size: int, num_instances: int, seed: Optional[int] = None):
        self.data_source = data_source
        self.num_instances = num_instances
        self.num_pids_per_batch = mini_batch_size // self.num_instances

        self._rank = comm.get_rank()
        self._world_size = comm.get_world_size()
        self.batch_size = mini_batch_size * self._world_size

        self.pid_index = defaultdict(list)
        self.domain = defaultdict(list)

        for index, info in enumerate(data_source):
            pid = info[1]
            # did = info[1].split('_')[0]
            self.pid_index[pid].append(index)
            # self.domain[did].append(pid)

        self.pids = sorted(list(self.pid_index.keys()))

        for pid in self.pids:
            did = pid.split('_')[0]
            self.domain[did].append(pid)

        self.num_identities = len(self.pids)

        if seed is None:
            seed = comm.shared_random_seed()
        self._seed = int(seed)

    def __iter__(self):
        start = self._rank
        yield from itertools.islice(self._infinite_indices(), start, None, self._world_size)

    def _infinite_indices(self):
        np.random.seed(self._seed)
        while True:
            avl_pids = copy.deepcopy(self.pids)
            domain = copy.deepcopy(self.domain)
            batch_idxs_dict = {}

            batch_indices = []
            while len(avl_pids) >= self.num_pids_per_batch and domain:
                for selected_domain in domain:
                # selected_domain = np.random.choice(list(domain.keys()), 1, replace=False).tolist()[0]
                    selected_pids = np.random.choice(domain[selected_domain], self.num_pids_per_batch, replace=False).tolist()
                    # selected_pids = np.random.choice(avl_pids, self.num_pids_per_batch, replace=False).tolist()
                    for pid in selected_pids:
                        # Register pid in batch_idxs_dict if not
                        if pid not in batch_idxs_dict:
                            idxs = copy.deepcopy(self.pid_index[pid])
                            if len(idxs) < self.num_instances:
                                idxs = np.random.choice(idxs, size=self.num_instances, replace=True).tolist()
                            np.random.shuffle(idxs)
                            batch_idxs_dict[pid] = idxs

                        avl_idxs = batch_idxs_dict[pid]
                        for _ in range(self.num_instances):
                            batch_indices.append(avl_idxs.pop(0))

                        if len(avl_idxs) < self.num_instances:
                            avl_pids.remove(pid)
                            domain[selected_domain].remove(pid)
                    # if len(domain[selected_domain]) < self.num_pids_per_batch:
                    #     del domain[selected_domain]


                if len(batch_indices) == self.batch_size:
                    yield from reorder_index(batch_indices, self._world_size)
                    batch_indices = []